{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_수아,epoch50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suajeong52/CNN/blob/main/cnn_%EC%88%98%EC%95%84%2Cepoch50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqRJCrUA7Rw-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization,  LeakyReLU, Dropout, Activation\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "NUM_CLASSES = 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P43vuJS_V7Qc",
        "outputId": "3056f66d-c40b-49cd-e0cb-0738ee29fc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train = x_train.astype('float32')/255.\n",
        "x_test  = x_test.astype('float32')/255.\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test  = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "OiruwspM7Vry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape = (32,32,3))\n",
        "\n",
        "conv_layer_1 = Conv2D(filters = 32\n",
        "                      , kernel_size = (3,3)\n",
        "                      , strides = 2\n",
        "                      , padding = 'same'\n",
        "                      , activation = 'relu'\n",
        "                      )(input_layer)\n",
        "\n",
        "conv_layer_2 = Conv2D(\n",
        "        filters = 46\n",
        "        , kernel_size = (3,3)\n",
        "        , strides = 2\n",
        "        , padding = 'same'\n",
        "        , activation = 'relu'\n",
        "        )(conv_layer_1)\n",
        "\n",
        "conv_layer_3 = Conv2D(\n",
        "        filters = 64\n",
        "        , kernel_size = (3,3)\n",
        "        , strides = 2\n",
        "        , padding = 'same'\n",
        "        , activation = 'relu'\n",
        "        )(conv_layer_2)\n",
        " \n",
        "flatten_layer = Flatten()(conv_layer_2)\n",
        "\n",
        "dense = Dense(128, activation = 'relu')(flatten_layer)\n",
        "#dropout = Dropout(rate = 0.5)(dense)\n",
        "\n",
        "output_layer = Dense(10, activation = 'softmax')(dense)\n",
        "\n",
        "model1 = Model(input_layer, output_layer)"
      ],
      "metadata": {
        "id": "KD0SQ3Ms8apZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kImgN71A8uAp",
        "outputId": "b1826955-b474-4fe2-fe6d-0e5f263019a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 16, 16, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 46)          13294     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2944)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               376960    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 392,440\n",
            "Trainable params: 392,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(lr=0.0005)\n",
        "model1.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics= ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l8fopZd9tjp",
        "outputId": "1197c7fe-ee51-4dce-d168-d7875f44fb98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(x_train, y_train, batch_size = 32, epochs = 50, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uu-oyk69wAR",
        "outputId": "02d9fa3f-74dd-420f-a1b2-8f0894cd3e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 1.5294 - accuracy: 0.4524\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 1.2299 - accuracy: 0.5650\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 1.1008 - accuracy: 0.6113\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 1.0018 - accuracy: 0.6491\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.9061 - accuracy: 0.6828\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 27s 18ms/step - loss: 0.8282 - accuracy: 0.7093\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7539 - accuracy: 0.7375\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.6858 - accuracy: 0.7592\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.6215 - accuracy: 0.7841\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 0.5574 - accuracy: 0.8057\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 0.4981 - accuracy: 0.8278\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 0.4425 - accuracy: 0.8473\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 26s 16ms/step - loss: 0.3854 - accuracy: 0.8674\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 0.3326 - accuracy: 0.8873\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 0.2855 - accuracy: 0.9035\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 0.2435 - accuracy: 0.9180\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 0.2055 - accuracy: 0.9312\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 0.1762 - accuracy: 0.9429\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 26s 16ms/step - loss: 0.1451 - accuracy: 0.9527\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 26s 16ms/step - loss: 0.1245 - accuracy: 0.9604\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.1139 - accuracy: 0.9635\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 26s 16ms/step - loss: 0.0912 - accuracy: 0.9710\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 26s 16ms/step - loss: 0.0882 - accuracy: 0.9721\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 0.0765 - accuracy: 0.9755\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0662 - accuracy: 0.9790\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0664 - accuracy: 0.9788\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0604 - accuracy: 0.9810\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0605 - accuracy: 0.9801\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0544 - accuracy: 0.9821\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0523 - accuracy: 0.9829\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0566 - accuracy: 0.9812\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0413 - accuracy: 0.9867\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0484 - accuracy: 0.9840\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0481 - accuracy: 0.9845\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0407 - accuracy: 0.9869\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0397 - accuracy: 0.9867\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0458 - accuracy: 0.9845\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0406 - accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0419 - accuracy: 0.9854\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0372 - accuracy: 0.9879\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0378 - accuracy: 0.9869\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0332 - accuracy: 0.9886\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 26s 16ms/step - loss: 0.0393 - accuracy: 0.9863\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 26s 16ms/step - loss: 0.0355 - accuracy: 0.9879\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0373 - accuracy: 0.9877\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0400 - accuracy: 0.9864\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0339 - accuracy: 0.9891\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0299 - accuracy: 0.9906\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0317 - accuracy: 0.9892\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0366 - accuracy: 0.9880\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6af6f1bad0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "W7HlUKdS_P84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a459c8-caff-40e5-d756-83dc07fb3f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 3.8197 - accuracy: 0.6262\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.819730758666992, 0.6262000203132629]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H6hOg2iYL3FM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}